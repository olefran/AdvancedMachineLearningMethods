{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41b7905f-a070-4ffe-abfc-67fbcd2adaa9",
   "metadata": {
    "id": "41b7905f-a070-4ffe-abfc-67fbcd2adaa9"
   },
   "source": [
    "## TC 5033\n",
    "## Deep Learning\n",
    "## Transformers\n",
    "\n",
    "Emmanuel Francisco González Velázquez - A01364577\n",
    "\n",
    "Oscar Israel Lerma Franco - A01380817\n",
    "\n",
    "Jesús Mario Martínez Díaz - A01740049\n",
    "\n",
    "Eduardo Selim Martínez Mayorga - A01795167\n",
    "\n",
    "José Antonio Hernández Hernández - A01381334\n",
    "\n",
    "#### Activity 4: Implementing a Translator\n",
    "\n",
    "- Objective\n",
    "\n",
    "To understand the Transformer Architecture by Implementing a translator.\n",
    "\n",
    "- Instructions\n",
    "\n",
    "    This activity requires submission in teams. While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n",
    "\n",
    "    Follow the provided code. The code already implements a transformer from scratch as explained in one of [week's 9 videos](https://youtu.be/XefFj4rLHgU)\n",
    "\n",
    "    Since the provided code already implements a simple translator, your job for this assignment is to understand it fully, and document it using pictures, figures, and markdown cells.  You should test your translator with at least 10 sentences. The dataset used for this task was obtained from [Tatoeba, a large dataset of sentences and translations](https://tatoeba.org/en/downloads).\n",
    "  \n",
    "- Evaluation Criteria\n",
    "\n",
    "    - Code Readability and Comments\n",
    "    - Traning a translator\n",
    "    - Translating at least 10 sentences.\n",
    "\n",
    "- Submission\n",
    "\n",
    "Submit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f54c65",
   "metadata": {
    "heading_collapsed": true,
    "id": "17f54c65"
   },
   "source": [
    "#### Script to convert csv to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f02c0c2",
   "metadata": {
    "hidden": true,
    "id": "8f02c0c2"
   },
   "outputs": [],
   "source": [
    "#This script requires to convert the TSV file to CSV\n",
    "# easiest way is to open it in Calc or excel and save as csv\n",
    "import pandas as pd\n",
    "PATH = '/content/Sentence pairs in English-Spanish - 2024-11-14.tsv'\n",
    "df = pd.read_csv(PATH, sep='\\t', on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787d9408",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "787d9408",
    "outputId": "8a609106-8eeb-4f2a-b2f3-ad93a7ed0c4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-3dc34c691c42>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()\n"
     ]
    }
   ],
   "source": [
    "eng_spa_cols = df.iloc[:, [1, 3]]\n",
    "eng_spa_cols['length'] = eng_spa_cols.iloc[:, 0].str.len()\n",
    "eng_spa_cols = eng_spa_cols.sort_values(by='length')\n",
    "eng_spa_cols = eng_spa_cols.drop(columns=['length'])\n",
    "\n",
    "output_file_path = '/content/Sentence pairs in English-Spanish - 2024-11-14.txt'\n",
    "eng_spa_cols.to_csv(output_file_path, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d468e9a",
   "metadata": {
    "id": "7d468e9a"
   },
   "source": [
    "## Transformer - Attention is all you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5dcf681",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5dcf681",
    "outputId": "12e8dfbb-7870-4d3f-bd8c-e15fac62be5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7cbdc1a5fdd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "torch.manual_seed(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c2cbd17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c2cbd17",
    "outputId": "a43274c6-6cef-48a5-9a41-b131113e88a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6623a1",
   "metadata": {
    "id": "9c6623a1"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118cc45a-6d59-45ea-8a5b-09e770d125f2",
   "metadata": {},
   "source": [
    "## PositionalEmbedding\n",
    "\n",
    "The `PositionalEmbedding` class implements positional encoding to add information about the position of tokens in a sequence to their embeddings.\n",
    "\n",
    "- **Attributes:**\n",
    "  - `pos_embed_matrix`: Precomputed matrix of positional embeddings based on sine and cosine functions.\n",
    "- **Initialization:**\n",
    "  - Computes the positional encoding for a sequence up to `max_seq_len` with embedding dimension `d_model`.\n",
    "- **Forward Pass:**\n",
    "  - Adds the positional embedding to the input tensor `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730bb8f-1105-4974-b27a-47ee396e1b92",
   "metadata": {},
   "source": [
    "## MultiHeadAttention\n",
    "\n",
    "The `MultiHeadAttention` class implements the multi-head attention mechanism.\n",
    "\n",
    "- **Attributes:**\n",
    "  - `W_q`, `W_k`, `W_v`: Linear transformations for queries, keys, and values.\n",
    "  - `W_o`: Linear transformation for the concatenated output of all heads.\n",
    "  - `d_k`, `d_v`: Dimensions of keys/values per head.\n",
    "  - `num_heads`: Number of attention heads.\n",
    "- **Methods:**\n",
    "  - `forward(Q, K, V, mask)`: Computes the multi-head attention, handling queries (`Q`), keys (`K`), and values (`V`).\n",
    "  - `scale_dot_product(Q, K, V, mask)`: Implements scaled dot-product attention.\n",
    "- **Forward Pass:**\n",
    "  - Splits input into multiple heads, computes attention, and recombines the heads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3134ff0-1e62-44b5-9b2b-13b6a6b9012e",
   "metadata": {},
   "source": [
    "## PositionFeedForward\n",
    "\n",
    "The `PositionFeedForward` class implements a two-layer feed-forward network used in Transformer layers.\n",
    "\n",
    "- **Attributes:**\n",
    "  - `linear1`, `linear2`: Fully connected layers.\n",
    "- **Forward Pass:**\n",
    "  - Applies a ReLU activation between the two linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3103d45f",
   "metadata": {
    "code_folding": [
     30,
     94
    ],
    "id": "3103d45f"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = MAX_SEQ_LEN):\n",
    "        super().__init__()\n",
    "        self.pos_embed_matrix = torch.zeros(max_seq_len, d_model, device=device)\n",
    "        token_pos = torch.arange(0, max_seq_len, dtype = torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n",
    "                             * (-math.log(10000.0)/d_model))\n",
    "        self.pos_embed_matrix[:, 0::2] = torch.sin(token_pos * div_term)\n",
    "        self.pos_embed_matrix[:, 1::2] = torch.cos(token_pos * div_term)\n",
    "        self.pos_embed_matrix = self.pos_embed_matrix.unsqueeze(0).transpose(0,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         print(self.pos_embed_matrix.shape)\n",
    "#         print(x.shape)\n",
    "        return x + self.pos_embed_matrix[:x.size(0), :]\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model = 512, num_heads = 8):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, 'Embedding size not compatible with num heads'\n",
    "\n",
    "        self.d_v = d_model // num_heads\n",
    "        self.d_k = self.d_v\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask = None):\n",
    "        batch_size = Q.size(0)\n",
    "        '''\n",
    "        Q, K, V -> [batch_size, seq_len, num_heads*d_k]\n",
    "        after transpose Q, K, V -> [batch_size, num_heads, seq_len, d_k]\n",
    "        '''\n",
    "        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n",
    "        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n",
    "        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n",
    "\n",
    "        weighted_values, attention = self.scale_dot_product(Q, K, V, mask)\n",
    "        weighted_values = weighted_values.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads*self.d_k)\n",
    "        weighted_values = self.W_o(weighted_values)\n",
    "\n",
    "        return weighted_values, attention\n",
    "\n",
    "\n",
    "    def scale_dot_product(self, Q, K, V, mask = None):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attention = F.softmax(scores, dim = -1)\n",
    "        weighted_values = torch.matmul(attention, V)\n",
    "\n",
    "        return weighted_values, attention\n",
    "\n",
    "\n",
    "class PositionFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(F.relu(self.linear1(x)))\n",
    "\n",
    "class EncoderSubLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = PositionFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.droupout1 = nn.Dropout(dropout)\n",
    "        self.droupout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        attention_score, _ = self.self_attn(x, x, x, mask)\n",
    "        x = x + self.droupout1(attention_score)\n",
    "        x = self.norm1(x)\n",
    "        x = x + self.droupout2(self.ffn(x))\n",
    "        return self.norm2(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class DecoderSubLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, encoder_output, target_mask=None, encoder_mask=None):\n",
    "        attention_score, _ = self.self_attn(x, x, x, target_mask)\n",
    "        x = x + self.dropout1(attention_score)\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        encoder_attn, _ = self.cross_attn(x, encoder_output, encoder_output, encoder_mask)\n",
    "        x = x + self.dropout2(encoder_attn)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = x + self.dropout3(ff_output)\n",
    "        return self.norm3(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([DecoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, encoder_output, target_mask, encoder_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, target_mask, encoder_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbbcc60-2ff6-40f6-a2f3-e17ef0b53974",
   "metadata": {},
   "source": [
    "## Sumary\n",
    "\n",
    "1. **Positional Encoding:**\n",
    "\n",
    "   - Adds positional information to token embeddings.\n",
    "   - Implemented using sine and cosine functions.\n",
    "\n",
    "2. **Multi-Head Attention:**\n",
    "\n",
    "   - Splits input into multiple attention heads to capture different aspects of the relationships between tokens.\n",
    "\n",
    "3. **Feed-Forward Network:**\n",
    "\n",
    "   - Provides additional processing between attention layers.\n",
    "\n",
    "4. **Encoder-Decoder Structure:**\n",
    "\n",
    "   - The encoder processes the input sequence.\n",
    "   - The decoder generates the output sequence, attending to both the input sequence (via cross-attention) and its own predictions.\n",
    "\n",
    "5. **Layer Normalization and Dropout:**\n",
    "\n",
    "   - Used to stabilize and regularize training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3d9f60-bdf5-4b2e-a31a-ab99ec3ac0d4",
   "metadata": {},
   "source": [
    "## Transformer class creation\n",
    "1. **Initialization (`__init__`):**\n",
    "   - Sets up the embeddings for source and target vocabularies.\n",
    "   - Includes positional embeddings for sequence order information.\n",
    "   - Constructs the encoder and decoder stacks.\n",
    "   - Adds a final output layer to map decoder outputs to target vocabulary predictions.\n",
    "\n",
    "2. **Forward Pass (`forward`):**\n",
    "   - Creates source and target masks to handle padding and autoregressive decoding.\n",
    "   - Embeds and applies positional encodings to source and target sequences.\n",
    "   - Processes the source sequence through the encoder to generate encoded representations.\n",
    "   - Passes the target sequence, encoder outputs, and masks through the decoder.\n",
    "   - Maps decoder outputs to predictions via the output layer.\n",
    "\n",
    "3. **Masking (`mask`):**\n",
    "   - Generates source and target masks to distinguish padding tokens.\n",
    "   - Applies a triangular mask to the target sequence for autoregressive decoding.\n",
    "   - Outputs both source and target masks.\n",
    "\n",
    "The `Transformer` class integrates these steps seamlessly, providing a robust implementation of the Transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61070162",
   "metadata": {
    "code_folding": [],
    "id": "61070162"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers,\n",
    "                 input_vocab_size, target_vocab_size, \n",
    "                 max_len=MAX_SEQ_LEN, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # Embedding layers for source and target vocabularies\n",
    "        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n",
    "        \n",
    "        # Positional embedding to provide positional information to tokens\n",
    "        self.pos_embedding = PositionalEmbedding(d_model, max_len)\n",
    "\n",
    "        # Encoder and decoder components of the Transformer\n",
    "        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
    "        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
    "\n",
    "        # Output linear layer to map decoder outputs to the target vocabulary size\n",
    "        self.output_layer = nn.Linear(d_model, target_vocab_size)\n",
    "        \n",
    "    def forward(self, source, target):\n",
    "        # Create masks for the source and target sequences\n",
    "        source_mask, target_mask = self.mask(source, target)\n",
    "\n",
    "        # Apply embedding and positional encoding to the source sequence\n",
    "        source = self.encoder_embedding(source) * math.sqrt(self.encoder_embedding.embedding_dim)\n",
    "        source = self.pos_embedding(source)\n",
    "\n",
    "        # Pass the encoded source sequence through the encoder\n",
    "        encoder_output = self.encoder(source, source_mask)\n",
    "\n",
    "        # Apply embedding and positional encoding to the target sequence\n",
    "        target = self.decoder_embedding(target) * math.sqrt(self.decoder_embedding.embedding_dim)\n",
    "        target = self.pos_embedding(target)\n",
    "\n",
    "        # Pass the target sequence and encoder output through the decoder\n",
    "        output = self.decoder(target, encoder_output, target_mask, source_mask)\n",
    "\n",
    "        # Apply the output layer to produce final predictions\n",
    "        return self.output_layer(output)\n",
    "        \n",
    "    def mask(self, source, target):\n",
    "        # Create a mask for the source sequence, marking non-padding tokens\n",
    "        source_mask = (source != 0).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Create a mask for the target sequence, marking non-padding tokens\n",
    "        target_mask = (target != 0).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # Generate a triangular mask for the target sequence to ensure autoregressive decoding\n",
    "        size = target.size(1)\n",
    "        no_mask = torch.tril(torch.ones((1, size, size), device=device)).bool()\n",
    "        target_mask = target_mask & no_mask\n",
    "\n",
    "        # Return both source and target masks\n",
    "        return source_mask, target_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6b2d4",
   "metadata": {
    "heading_collapsed": true,
    "id": "6da6b2d4"
   },
   "source": [
    "#### Simple test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e3635-5160-4ae9-b126-03c3a2343f03",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "1. Parameters:\n",
    "   - `seq_len_source` and `seq_len_target` define the lengths of the sequences.\n",
    "   - `batch_size` determines the number of sequences in a batch.\n",
    "   - `input_vocab_size` and `target_vocab_size` specify the size of the cabularies for the source and target.\n",
    "2. Random Sequence Generation:\n",
    "   - torch.randint`(start, end, size)` generates a tensor with random integers \n",
    "     in the range [start, end) with the specified size.\n",
    "3. Output:\n",
    "   - source and target tensors represent the generated sequences for the urce and target respectively.\n",
    "   - This setup is often used to simulate input-output pairs for quence-based models during prototyping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40581d6",
   "metadata": {
    "hidden": true,
    "id": "d40581d6"
   },
   "outputs": [],
   "source": [
    "seq_len_source = 10\n",
    "seq_len_target = 10\n",
    "batch_size = 2\n",
    "input_vocab_size = 50\n",
    "target_vocab_size = 50\n",
    "\n",
    "source = torch.randint(1, input_vocab_size, (batch_size, seq_len_source))\n",
    "target = torch.randint(1, target_vocab_size, (batch_size, seq_len_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa052b-c81c-46c2-8aca-4e7dcc079dd6",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "1. Parameters for the Transformer model:\n",
    "   - `d_model`: Dimensionality of the model embeddings (512).\n",
    "   - `num_heads`: Number of attention heads in the multi-head attention mechanism (8).\n",
    "   - `d_ff`: Dimensionality of the feed-forward network (2048).\n",
    "   - `num_layers`: Number of layers in the Transformer encoder/decoder stack (6).\n",
    "2. Model Initialization:\n",
    "   - Transformer(d_model, num_heads, d_ff, num_layers, input_vocab_size, \n",
    "     target_vocab_size, max_len, dropout) initializes a Transformer model with the\n",
    "     specified parameters, vocabulary sizes, sequence length, and dropout rate.\n",
    "3. Device Placement:\n",
    "   - model.to(device): Moves the model to the specified device (e.g., CPU or GPU).\n",
    "   - source.to(device) and target.to(device): Move the source and target tensors\n",
    "     to the same device as the model for compatibility during training or inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc7cf689",
   "metadata": {
    "hidden": true,
    "id": "fc7cf689"
   },
   "outputs": [],
   "source": [
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "num_layers = 6\n",
    "\n",
    "model = Transformer(d_model, num_heads, d_ff, num_layers,\n",
    "                  input_vocab_size, target_vocab_size,\n",
    "                  max_len=MAX_SEQ_LEN, dropout=0.1)\n",
    "\n",
    "model = model.to(device)\n",
    "source = source.to(device)\n",
    "target = target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4618560e",
   "metadata": {
    "hidden": true,
    "id": "4618560e"
   },
   "outputs": [],
   "source": [
    "output = model(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab0bc69d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "ab0bc69d",
    "outputId": "c5829bf1-9783-45a6-9b21-73493d41e372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ouput.shape torch.Size([2, 10, 50])\n"
     ]
    }
   ],
   "source": [
    "# Expected output shape -> [batch, seq_len_target, target_vocab_size] i.e. [2, 10, 50]\n",
    "print(f'ouput.shape {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4b2910",
   "metadata": {
    "id": "0f4b2910"
   },
   "source": [
    "### Translator Eng-Spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "869a7244",
   "metadata": {
    "id": "869a7244"
   },
   "outputs": [],
   "source": [
    "PATH = '/content/Sentence pairs in English-Spanish - 2024-11-14.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0af1eba",
   "metadata": {
    "id": "d0af1eba"
   },
   "outputs": [],
   "source": [
    "with open(PATH, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "eng_spa_pairs = [line.strip().split('\\t') for line in lines if '\\t' in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c930226f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c930226f",
    "outputId": "06526e9b-a2ec-4ce8-e32e-1947df409904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['OK.', 'Bueno.'],\n",
       " ['Hi.', '¡Hola!'],\n",
       " ['Go!', '¡Ve!'],\n",
       " ['Hi.', 'Hola.'],\n",
       " ['So?', '¿Entonces?'],\n",
       " ['So?', '¿Y qué?'],\n",
       " ['So?', '¿Y?'],\n",
       " ['OK.', '¡Órale!'],\n",
       " ['Go.', 'Vete.'],\n",
       " ['Go.', 'Vaya.']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_spa_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "095f4037",
   "metadata": {
    "id": "095f4037"
   },
   "outputs": [],
   "source": [
    "eng_sentences = [pair[0] for pair in eng_spa_pairs]\n",
    "spa_sentences = [pair[1] for pair in eng_spa_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d9e1c95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d9e1c95",
    "outputId": "334ff859-9e3e-4d62-a9ff-7bed8ecad7d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OK.', 'Hi.', 'Go!', 'Hi.', 'So?', 'So?', 'So?', 'OK.', 'Go.', 'Go.']\n",
      "['Bueno.', '¡Hola!', '¡Ve!', 'Hola.', '¿Entonces?', '¿Y qué?', '¿Y?', '¡Órale!', 'Vete.', 'Vaya.']\n"
     ]
    }
   ],
   "source": [
    "print(eng_sentences[:10])\n",
    "print(spa_sentences[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60d11478",
   "metadata": {
    "id": "60d11478"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[á]+\", \"a\", sentence)\n",
    "    sentence = re.sub(r\"[é]+\", \"e\", sentence)\n",
    "    sentence = re.sub(r\"[í]+\", \"i\", sentence)\n",
    "    sentence = re.sub(r\"[ó]+\", \"o\", sentence)\n",
    "    sentence = re.sub(r\"[ú]+\", \"u\", sentence)\n",
    "    sentence = re.sub(r\"[^a-z]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = '<sos> ' + sentence + ' <eos>'\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "478f673b",
   "metadata": {
    "id": "478f673b"
   },
   "outputs": [],
   "source": [
    "s1 = '¿Hola @ cómo estás? 123'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96ac79c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96ac79c5",
    "outputId": "eda40f6e-231e-492c-fc15-4d54042deeb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Hola @ cómo estás? 123\n",
      "<sos> hola como estas <eos>\n"
     ]
    }
   ],
   "source": [
    "print(s1)\n",
    "print(preprocess_sentence(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9fc9c4d",
   "metadata": {
    "id": "d9fc9c4d"
   },
   "outputs": [],
   "source": [
    "eng_sentences = [preprocess_sentence(sentence) for sentence in eng_sentences]\n",
    "spa_sentences = [preprocess_sentence(sentence) for sentence in spa_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7a3b18d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7a3b18d",
    "outputId": "f5629e0a-210f-40cd-bd9a-cb3934cd6ff3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos> bueno <eos>',\n",
       " '<sos> hola <eos>',\n",
       " '<sos> ve <eos>',\n",
       " '<sos> hola <eos>',\n",
       " '<sos> entonces <eos>',\n",
       " '<sos> y que <eos>',\n",
       " '<sos> y <eos>',\n",
       " '<sos> orale <eos>',\n",
       " '<sos> vete <eos>',\n",
       " '<sos> vaya <eos>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spa_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97931cd3",
   "metadata": {
    "id": "97931cd3"
   },
   "outputs": [],
   "source": [
    "def build_vocab(sentences):\n",
    "    words = [word for sentence in sentences for word in sentence.split()]\n",
    "    word_count = Counter(words)\n",
    "    sorted_word_counts = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
    "    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fa8738e",
   "metadata": {
    "id": "7fa8738e"
   },
   "outputs": [],
   "source": [
    "eng_word2idx, eng_idx2word = build_vocab(eng_sentences)\n",
    "spa_word2idx, spa_idx2word = build_vocab(spa_sentences)\n",
    "eng_vocab_size = len(eng_word2idx)\n",
    "spa_vocab_size = len(spa_word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79d6b633",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79d6b633",
    "outputId": "1d05efa8-cdc7-4f8a-a79c-8768be72cf78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27651 46929\n"
     ]
    }
   ],
   "source": [
    "print(eng_vocab_size, spa_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b87d5-fdff-4d0a-94b2-7350dedd44ed",
   "metadata": {},
   "source": [
    "## Explanation:\n",
    "1. Initialization (__init__ method):\n",
    "   - `eng_sentences` and `spa_sentences`: Lists of English and Spanish sentences respectively.\n",
    "   - `eng_word2idx` and `spa_word2idx`: Dictionaries mapping words to their corresponding indices.\n",
    "2. Length (__len__ method):\n",
    "   - Returns the total number of English-Spanish sentence pairs in the dataset.\n",
    "3. Accessing Items (__getitem__ method):\n",
    "   - Retrieves a sentence pair (English and Spanish) at a specified index (idx).\n",
    "   - Tokenizes the sentences into words and maps each word to its index using the word2idx dictionaries.\n",
    "   - If a word is not found in the dictionary, it defaults to the index of the `<unk>` (unknown) token.\n",
    "   - Converts the resulting lists of indices into PyTorch tensors for use in training or inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e564017c",
   "metadata": {
    "id": "e564017c"
   },
   "outputs": [],
   "source": [
    "class EngSpaDataset(Dataset):\n",
    "    def __init__(self, eng_sentences, spa_sentences, eng_word2idx, spa_word2idx):\n",
    "        self.eng_sentences = eng_sentences\n",
    "        self.spa_sentences = spa_sentences\n",
    "        self.eng_word2idx = eng_word2idx\n",
    "        self.spa_word2idx = spa_word2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.eng_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng_sentence = self.eng_sentences[idx]\n",
    "        spa_sentence = self.spa_sentences[idx]\n",
    "        # return tokens idxs\n",
    "        eng_idxs = [self.eng_word2idx.get(word, self.eng_word2idx['<unk>']) for word in eng_sentence.split()]\n",
    "        spa_idxs = [self.spa_word2idx.get(word, self.spa_word2idx['<unk>']) for word in spa_sentence.split()]\n",
    "\n",
    "        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750cda9-c65e-4c9d-9bfb-f6e75f824ad2",
   "metadata": {},
   "source": [
    "1. Input:\n",
    "   - `batch`: A list of tuples, where each tuple contains an English sentence tensor and a Spanish sentence tensor.\n",
    "\n",
    "2. Unpacking:\n",
    "   - `eng_batch` and `spa_batch`: Unzip the batch into separate lists for English and Spanish sequences.\n",
    "\n",
    "3. Truncation:\n",
    "   - Each sequence in eng_batch and spa_batch is truncated to a maximum length (`MAX_SEQ_LEN`) to ensure uniform ngth.\n",
    "   - clone().detach(): Ensures the tensor is detached from its computation graph and cloned to avoid in-place erations.\n",
    "\n",
    "4. Padding:\n",
    "   - torch.nn.utils.rnn.pad_sequence is used to pad the sequences in each batch to the same length.\n",
    "   - batch_first=True ensures the padded tensors have dimensions `(batch_size, seq_len)`.\n",
    "   - padding_value=0 specifies the value used for padding.\n",
    "\n",
    "5. Output:\n",
    "   - eng_batch: A padded tensor of English sentence indices with dimensions `(batch_size, max_seq_len)`.\n",
    "   - spa_batch: A padded tensor of Spanish sentence indices with dimensions `(batch_size, max_seq_len)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b579577b",
   "metadata": {
    "id": "b579577b"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    eng_batch, spa_batch = zip(*batch)\n",
    "    eng_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n",
    "    spa_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n",
    "    eng_batch = torch.nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=0)\n",
    "    spa_batch = torch.nn.utils.rnn.pad_sequence(spa_batch, batch_first=True, padding_value=0)\n",
    "    return eng_batch, spa_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c70f890-03fc-4c62-8a6b-06a0d12c379e",
   "metadata": {},
   "source": [
    "## Model training\n",
    "1. Parameters:\n",
    "   - model: The sequence-to-sequence model to be trained.\n",
    "   - dataloader: A PyTorch DataLoader that provides batches of English and Spanish sequences.\n",
    "   - loss_function: The criterion to compute the loss (e.g., CrossEntropyLoss).\n",
    "   - optimiser: The optimizer used for updating model parameters (e.g., Adam).\n",
    "   - epochs: Number of training epochs.\n",
    "2. Training Setup:\n",
    "   - model.train(): Sets the model to training mode.\n",
    "   - total_loss: Accumulates the total loss over all batches in an epoch.\n",
    "3. Batch Processing:\n",
    "   - eng_batch and spa_batch: Batches of English and Spanish sequences moved to the specified device.\n",
    "   - target_input: Prepared by slicing spa_batch to exclude the last token (decoder input).\n",
    "   - target_output: Prepared by slicing spa_batch to exclude the first token and flattening the tensor.\n",
    "4. Forward Pass:\n",
    "   - model(eng_batch, target_input): Runs the model with English inputs and decoder inputs.\n",
    "   - output: Reshaped to match the dimensions required by the loss function.\n",
    "5. Loss Calculation:\n",
    "   - loss_function(output, target_output): Computes the loss between the model output and target output.\n",
    "6. Backpropagation and Optimization:\n",
    "   - loss.backward(): Computes the gradients.\n",
    "   - optimiser.step(): Updates the model parameters using the computed gradients.\n",
    "   - optimiser.zero_grad(): Resets gradients for the next iteration.\n",
    "7. Epoch Summary:\n",
    "   - avg_loss: The average loss over all batches in an epoch.\n",
    "   - Prints the epoch number and average loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d514b7c",
   "metadata": {
    "id": "8d514b7c"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_function, optimiser, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, (eng_batch, spa_batch) in enumerate(dataloader):\n",
    "            eng_batch = eng_batch.to(device)\n",
    "            spa_batch = spa_batch.to(device)\n",
    "            # Decoder preprocessing\n",
    "            target_input = spa_batch[:, :-1]\n",
    "            target_output = spa_batch[:, 1:].contiguous().view(-1)\n",
    "            # Zero grads\n",
    "            optimiser.zero_grad()\n",
    "            # run model\n",
    "            output = model(eng_batch, target_input)\n",
    "            output = output.view(-1, output.size(-1))\n",
    "            # loss\\\n",
    "            loss = loss_function(output, target_output)\n",
    "            # gradient and update parameters\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss/len(dataloader)\n",
    "        print(f'Epoch: {epoch}/{epochs}, Loss: {avg_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3732388-b17d-4201-bb4c-3f035db4fa11",
   "metadata": {},
   "source": [
    "1. Batch Size:\n",
    "   - `BATCH_SIZE` = 64: Specifies the number of samples per batch.\n",
    "2. Dataset:\n",
    "   - `EngSpaDataset`: A custom dataset containing English and Spanish sentence pairs.\n",
    "   - `eng_sentences` and `spa_sentences`: Lists of English and Spanish sentences.\n",
    "   - `eng_word2idx` and `spa_word2idx`: Word-to-index mappings for English and Spanish vocabularies.\n",
    "3. DataLoader:\n",
    "   - DataLoader(dataset, batch_size, shuffle, collate_fn):\n",
    "     - dataset: The `EngSpaDataset` instance that provides sentence pairs.\n",
    "     - batch_size: Number of samples per batch (64 in this case).\n",
    "     - shuffle=True: Randomizes the order of samples in each epoch for better training.\n",
    "     - collate_fn: A custom collate function for preprocessing batches (e.g., truncation and padding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2379ea72",
   "metadata": {
    "id": "2379ea72"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = EngSpaDataset(eng_sentences, spa_sentences, eng_word2idx, spa_word2idx)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25334206-b582-4704-80d8-5f4d2d3b4e9c",
   "metadata": {},
   "source": [
    "1. Parameters:\n",
    "   - `d_model`: Defines the size of the model's embedding vectors (512).\n",
    "   - `num_heads`: Sets the number of heads in the multi-head attention mechanism (8).\n",
    "   - `d_ff`: Specifies the dimensionality of the feed-forward layer (2048).\n",
    "   - `num_layers`: The number of encoder and decoder layers in the Transformer (6).\n",
    "   - `input_vocab_size`: Vocabulary size for the source language (e.g., English).\n",
    "   - `target_vocab_size`: Vocabulary size for the target language (e.g., Spanish).\n",
    "   - `max_len`: The maximum sequence length supported by the model.\n",
    "   - `dropout`: The dropout rate applied during training (0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e08eef6a",
   "metadata": {
    "id": "e08eef6a"
   },
   "outputs": [],
   "source": [
    "model = Transformer(d_model=512, num_heads=8, d_ff=2048, num_layers=6,\n",
    "                    input_vocab_size=eng_vocab_size, target_vocab_size=spa_vocab_size,\n",
    "                    max_len=MAX_SEQ_LEN, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1181a12",
   "metadata": {
    "id": "a1181a12"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14e265e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14e265e9",
    "outputId": "61c8650b-e74b-41e6-ca13-dbfe02003116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10, Loss: 3.5947\n",
      "Epoch: 1/10, Loss: 2.2026\n",
      "Epoch: 2/10, Loss: 1.7022\n",
      "Epoch: 3/10, Loss: 1.3742\n",
      "Epoch: 4/10, Loss: 1.1222\n",
      "Epoch: 5/10, Loss: 0.9198\n",
      "Epoch: 6/10, Loss: 0.7546\n",
      "Epoch: 7/10, Loss: 0.6260\n",
      "Epoch: 8/10, Loss: 0.5306\n",
      "Epoch: 9/10, Loss: 0.4632\n"
     ]
    }
   ],
   "source": [
    "train(model, dataloader, loss_function, optimiser, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9005412f-530f-4462-9f46-bb9b6bd681d9",
   "metadata": {
    "id": "1d271146"
   },
   "source": [
    "1. Data preparation functions:\n",
    "   - sentence_to_indices: Converts a sentence into a list of word indices using a word2idx mapping.\n",
    "   - indices_to_sentence: Converts a list of word indices back into a readable sentence using an idx2word mapping.\n",
    "\n",
    "2. Translation Function:\n",
    "   - Preprocesses and tokenizes an input sentence.\n",
    "   - Generates an output sequence using the Transformer model.\n",
    "   - Stops when the <eos> (end-of-sequence) token is generated or when the maximum sequence length is reached.\n",
    "   - Converts the generated indices back to a readable sentence.\n",
    "   - Copiar código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50740746",
   "metadata": {
    "code_folding": [],
    "id": "50740746"
   },
   "outputs": [],
   "source": [
    "def sentence_to_indices(sentence, word2idx):\n",
    "    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n",
    "\n",
    "def indices_to_sentence(indices, idx2word):\n",
    "    return ' '.join([idx2word[idx] for idx in indices if idx in idx2word and idx2word[idx] != '<pad>'])\n",
    "\n",
    "def translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
    "    model.eval()\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input_indices = sentence_to_indices(sentence, eng_word2idx)\n",
    "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n",
    "\n",
    "    # Initialize the target tensor with <sos> token\n",
    "    tgt_indices = [spa_word2idx['<sos>']]\n",
    "    tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            output = model(input_tensor, tgt_tensor)\n",
    "            output = output.squeeze(0)\n",
    "            next_token = output.argmax(dim=-1)[-1].item()\n",
    "            tgt_indices.append(next_token)\n",
    "            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
    "            if next_token == spa_word2idx['<eos>']:\n",
    "                break\n",
    "\n",
    "    return indices_to_sentence(tgt_indices, spa_idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef70d33-f516-4a89-9991-8022705a51ca",
   "metadata": {},
   "source": [
    "## Evaluate_translations function:\n",
    "\n",
    "- Takes a trained model and a list of input sentences.\n",
    "- Translates each sentence using the translate_sentence function.\n",
    "- Prints the original sentence and its translation in Spanish.\n",
    "- Example Sentences are given\n",
    "\n",
    "- The model is moved to the specified device, and translations are evaluated and displayed in the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2c0db72",
   "metadata": {
    "code_folding": [
     15
    ],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2c0db72",
    "outputId": "f59d8200-b8c7-4752-91d3-94c72933f89c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Hello, how are you?\n",
      "Traducción: <sos> hola como estas <eos>\n",
      "\n",
      "Input sentence: I am learning artificial intelligence.\n",
      "Traducción: <sos> estoy aprendiendo inteligencia artificial <eos>\n",
      "\n",
      "Input sentence: Artificial intelligence is great.\n",
      "Traducción: <sos> la inteligencia artificial es buenisima <eos>\n",
      "\n",
      "Input sentence: Good night!\n",
      "Traducción: <sos> buenas noches <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_translations(model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
    "    for sentence in sentences:\n",
    "        translation = translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len, device)\n",
    "        print(f'Input sentence: {sentence}')\n",
    "        print(f'Traducción: {translation}')\n",
    "        print()\n",
    "\n",
    "# Example sentences to test the translator\n",
    "test_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I am learning artificial intelligence.\",\n",
    "    \"Artificial intelligence is great.\",\n",
    "    \"Good night!\"\n",
    "]\n",
    "\n",
    "# Assuming the model is trained and loaded\n",
    "# Set the device to 'cpu' or 'cuda' as needed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Evaluate translations\n",
    "evaluate_translations(model, test_sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ceefe95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ceefe95",
    "outputId": "f93b7dcb-ff24-4e33-933b-c69bfab85828"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: I want to pass this course\n",
      "Traducción: <sos> quiero pasar este curso <eos>\n",
      "\n",
      "Input sentence: I have two brothers\n",
      "Traducción: <sos> tengo dos hermanos <eos>\n",
      "\n",
      "Input sentence: We are from Mexico\n",
      "Traducción: <sos> somos de mexico <eos>\n",
      "\n",
      "Input sentence: This is an interesting homework\n",
      "Traducción: <sos> este es un tarea interesante <eos>\n",
      "\n",
      "Input sentence: The sun is shining brightly today\n",
      "Traducción: <sos> el sol esta brillando intensamente hoy <eos>\n",
      "\n",
      "Input sentence: My favorite sport is Baseball\n",
      "Traducción: <sos> el beisbol es mi deporte favorito <eos>\n",
      "\n",
      "Input sentence: Today we do some homework\n",
      "Traducción: <sos> hoy hacemos un poco de tarea <eos>\n",
      "\n",
      "Input sentence: I need to learn more languajes\n",
      "Traducción: <sos> necesito aprender mas para aprender <eos>\n",
      "\n",
      "Input sentence: I like to listening to music\n",
      "Traducción: <sos> me gusta escuchar musica <eos>\n",
      "\n",
      "Input sentence: The man studies in the school\n",
      "Traducción: <sos> el hombre estudia en la escuela <eos>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_translations(model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
    "    for sentence in sentences:\n",
    "        translation = translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len, device)\n",
    "        print(f'Input sentence: {sentence}')\n",
    "        print(f'Traducción: {translation}')\n",
    "        print()\n",
    "\n",
    "# Example sentences to test the translator\n",
    "test_sentences = [\n",
    "    \"I want to pass this course\",\n",
    "    \"I have two brothers\",\n",
    "    \"We are from Mexico\",\n",
    "    \"This is an interesting homework\",\n",
    "    \"The sun is shining brightly today\",\n",
    "    \"My favorite sport is Baseball\",\n",
    "    \"Today we do some homework\",\n",
    "    \"I need to learn more languajes\",\n",
    "    \"I like to listening to music\",\n",
    "    \"The man studies in the school\"\n",
    "]\n",
    "\n",
    "# Assuming the model is trained and loaded\n",
    "# Set the device to 'cpu' or 'cuda' as needed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Evaluate translations\n",
    "evaluate_translations(model, test_sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce60ec-6a52-4968-a355-9d1e21984ad7",
   "metadata": {
    "id": "a7e10a50"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "The interesting first hurdle was the training data (Sentence pairs in English-Spanish - 2024-11-14.tsv) , originally expected to be parsed with tab (\\t) characters, on line 11864 the format seems to break, either deleting the line or reconstructing it with tabs manually solves the problem (which apparently only happened on some systems). \n",
    "\n",
    "The second challenge was, of course the training function, using local hardware did not appear to work as well as it used to, giving the error: \n",
    "\n",
    "```CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 7.78 GiB total capacity; 7.16 GiB already allocated; 14.38 MiB free; 7.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation. See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF```\n",
    "\n",
    "(The error above was of course an out of memory exception on the local graphic card.)\n",
    "The solution seemed at first modification of the layers of the model, which did not turn out to be a satisfactory result, at first, given the training time was still an issue. Reliant on a more powerful graphics card, training took about 54 minutes. \n",
    "\n",
    "Modifying the batch size and the os environment variable ‘max_split_size_mb’ did in fact help solve the problem of a memory exception.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
